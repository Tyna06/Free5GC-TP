# Universit√© Paris Cit√©  
## Master Informatique ‚Äì R√©seaux et Syst√®mes Autonomes  
### Ann√©e universitaire 2024‚Äì2025  

---

# **Rapport de TP : D√©ploiement de Free5GC sur Kubernetes (KinD)**  
Module : **IFRCE015 ‚Äì R√©seaux 5G et Virtualisation**

---

## **√âtudiante**  
- **Ziane Thinhinane**  

## **Enseignant**  
[Nom du professeur]

---

*(Ce document pr√©sente le travail r√©alis√© dans le cadre du TP portant sur l‚Äôinstallation et le d√©ploiement d‚Äôun c≈ìur 5G open source Free5GC dans un environnement Kubernetes bas√© sur KinD.)*

---

## Table des mati√®res
- [Introduction](#introduction)
- [1. Installation de la machine virtuelle](#1-installation-de-la-machine-virtuelle)
  - [1.1 Cr√©ation de la machine virtuelle](#11-cr√©ation-de-la-machine-virtuelle)
  - [1.2 Installation du syst√®me Ubuntu](#12-installation-du-syst√®me-ubuntu)
  - [1.3 Configuration de l‚Äôacc√®s SSH](#13-configuration-de-lacc√®s-ssh)
- [2. Installation des d√©pendances](#2-installation-des-d√©pendances)
- [3. Cr√©ation du cluster KinD](#3-cr√©ation-du-cluster-kind)
- [4. Installation du CNI et de Multus](#4-installation-du-cni-et-de-multus)
- [5. Configuration Free5GC](#5-configuration-free5gc)
- [6. D√©ploiement Free5GC](#6-d√©ploiement-free5gc)
- [7. D√©ploiement UERANSIM](#7-d√©ploiement-ueransim)
- [8. Probl√®mes rencontr√©s](#8-probl√®mes-rencontr√©s)
- [Conclusion](#conclusion)

---

# Introduction

Ce rapport pr√©sente l‚Äôensemble des √©tapes n√©cessaires pour installer et d√©ployer **Free5GC**, un c≈ìur 5G open-source, sur un cluster Kubernetes bas√© sur **KinD**.  
L‚Äôobjectif principal de ce TP est de comprendre :

- la mise en place d‚Äôun environnement virtualis√© ;
- l‚Äôinstallation de Docker, Kind, Kubectl et Helm ;
- la gestion des r√©seaux CNI et l‚Äôajout de Multus ;
- le d√©ploiement complet de Free5GC ;
- l‚Äôex√©cution d‚ÄôUE simul√©s via UERANSIM ;
- ainsi que l‚Äôanalyse des probl√®mes rencontr√©s et leurs solutions.

Toutes les √©tapes sont illustr√©es par des captures d‚Äô√©cran et accompagn√©es de commentaires d√©taill√©s afin de fournir une documentation claire et p√©dagogique.

---

# 1. Installation de la machine virtuelle

Pour commencer ce TP, j‚Äôai t√©l√©charg√© l‚Äôimage ISO de **Ubuntu Server 24.04 LTS** depuis le site officiel.  
Cette version est l√©g√®re, stable et compatible avec les outils n√©cessaires au d√©ploiement de Free5GC.

La premi√®re √©tape a consist√© √† cr√©er une **machine virtuelle (VM)** √† partir de cette image ISO.  
Pour cela, j‚Äôai utilis√© **VMware Workstation**, en s√©lectionnant l‚Äôoption *Create a New Virtual Machine*, puis en important l‚Äôimage ISO pr√©c√©demment t√©l√©charg√©e.

Les sous-sections suivantes d√©crivent en d√©tail toutes les √©tapes de cr√©ation et configuration de cette VM.

---

## 1.1 Cr√©ation de la machine virtuelle

![Cr√©ation de la VM](./instalations_vm/01_vm_creation_start.png)

![Cr√©ation ‚Äì √âtape suivante](./instalations_vm/01_01_vm_creation_start.png)

![S√©lection de l‚ÄôISO](./instalations_vm/02_select_iso.png)
![Choix du nom et de l‚Äôemplacement](./instalations_vm/01_01_02vm_name_selection.png)


![Configuration CPU/RAM](./instalations_vm/03_vm_resources.png)

Dans cette √©tape, j‚Äôai augment√© la taille du disque √† **50 Go** afin de pr√©voir suffisamment d‚Äôespace pour les images Docker, Kubernetes et Free5GC.

![Configuration du disque](./instalations_vm/04_vm_disk.png)

J‚Äôai √©galement configur√© **6 Go de RAM**, ce qui est recommand√© pour ce TP en raison des ressources n√©cessaires pour faire tourner KinD et Free5GC.

![Premier boot Ubuntu](./instalations_vm/05_ubuntu_boot.png)

Cette capture montre la fin de la configuration et le lancement du syst√®me depuis l‚ÄôISO Ubuntu Server.

---

## 1.2 Installation du syst√®me Ubuntu

Apr√®s le d√©marrage sur l‚Äôimage ISO, j‚Äôai suivi les √©tapes d‚Äôinstallation de **Ubuntu Server**, notamment :

- choix de la langue et du clavier ;
- configuration automatique du r√©seau ;
- installation standard du syst√®me ;
- activation de l‚Äôoption **OpenSSH Server** pour pouvoir utiliser SSH ;
- cr√©ation de l‚Äôutilisateur administrateur ;
- test de connexion apr√®s installation.

Voici les captures d‚Äô√©cran illustrant le d√©roulement complet de l‚Äôinstallation :

![Installation Ubuntu ‚Äì √©cran 1](./instalations_vm/06_install_ubuntu_screen.png)
![Installation Ubuntu ‚Äì √©tape 2](./instalations_vm/06_install_ubuntu_2.png)
![Installation Ubuntu ‚Äì √©tape 3](./instalations_vm/06_install_ubuntu_3.png)
![Installation Ubuntu ‚Äì √©tape 4](./instalations_vm/06_install_ubuntu_4.png)
![Installation Ubuntu ‚Äì √©tape 5](./instalations_vm/06_install_ubuntu_5.png)
![Installation Ubuntu ‚Äì √©tape 6](./instalations_vm/06_install_ubuntu_6.png)
![Installation Ubuntu ‚Äì √©tape 7](./instalations_vm/06_install_ubuntu_7.png)
![Installation Ubuntu ‚Äì √©tape 8](./instalations_vm/06_install_ubuntu_8.png)
![Installation Ubuntu ‚Äì √©tape 9](./instalations_vm/06_install_ubuntu_9.png)
![Installation Ubuntu ‚Äì √©tape 10](./instalations_vm/06_install_ubuntu_10.png)
![Installation Ubuntu ‚Äì √©tape 11](./instalations_vm/06_install_ubuntu_11.png)
![Installation Ubuntu ‚Äì √©tape 12](./instalations_vm/06_install_ubuntu_12.png)
![Installation Ubuntu ‚Äì √©tape 13](./instalations_vm/06_install_ubuntu_13.png)

---
## 1.3 Configuration de l‚Äôacc√®s SSH √† la machine virtuelle

Avant de commencer l‚Äôinstallation des d√©pendances (Docker, Kind, Kubectl, Helm), j‚Äôai configur√© un acc√®s SSH afin de pouvoir travailler plus confortablement depuis mon ordinateur h√¥te.  
L‚Äôacc√®s SSH permet notamment :

- d‚Äôutiliser un terminal plus lisible que celui de VMware ;
- de copier/coller facilement les commandes du TP ;
- d‚Äôouvrir plusieurs sessions en parall√®le si n√©cessaire ;
- de travailler comme sur un serveur distant r√©el.

---

### 1.3.1 Activation du service SSH

Lors de la premi√®re v√©rification, le service SSH √©tait install√© mais d√©sactiv√©.  
Je l‚Äôai activ√© puis d√©marr√© avec les commandes suivantes :

<!-- ligne code  -->
```bash 
sudo systemctl enable ssh
sudo systemctl start ssh
sudo systemctl status ssh

```


Apr√®s activation, le service passe correctement √† l‚Äô√©tat **active (running)** :

![Service SSH actif](./redirection_ssh/01_status_ssh_runing.png)

---

### 1.3.2 R√©cup√©ration de l‚Äôadresse IP de la VM (mode NAT)

J‚Äôutilise le mode NAT de VMware.  
Pour r√©cup√©rer l‚Äôadresse IP interne attribu√©e par VMware :

<!-- code  -->
``` bash
ip a
```


L‚Äôadresse IP appara√Æt sous l‚Äôinterface `ens33`.

![Adresse IP de la VM](./redirection_ssh/02_vm_ip_address.png)

---

### 1.3.3 Configuration de la redirection NAT (port forwarding)

VMware utilise l‚Äôinterface **VMnet8** pour le mode NAT.  
Pour exposer la VM via `127.0.0.1`, j‚Äôai configur√© une redirection du port **2222 ‚Üí 22** :

- **Host port : 2222**
- **Virtual machine IP : 192.168.5.136** (IP obtenue pr√©c√©demment)
- **Virtual machine port : 22 (SSH)**

#### Acc√®s aux param√®tres r√©seau

![Ouverture du Virtual Network Editor](./redirection_ssh/03_vmware_nat.png)

#### S√©lection de VMnet8 (NAT)

![S√©lection VMnet8](./redirection_ssh/04_vmware_nat.png)

#### Acc√®s aux param√®tres NAT

![Bouton NAT Settings](./redirection_ssh/05_vmware_nat.png)

#### Ajout de la r√®gle de redirection

![Ajout du port 2222](./redirection_ssh/06_vmware_nat.png)


---

### 1.3.4 Connexion SSH via Git Bash (localhost)

Windows ne disposant pas du client OpenSSH, j‚Äôai utilis√© **Git Bash**, qui inclut un client SSH complet.  
La connexion s‚Äôeffectue directement via localhost :

```` bash
ssh tyna@127.0.0.1 -p 2222
````

Apr√®s validation de la cl√© et saisie du mot de passe, la connexion r√©ussit :

![Connexion SSH r√©ussie](./redirection_ssh/07_vmware_nat.png)

---
# 2. Installation des d√©pendances

Avant de pouvoir cr√©er un cluster Kubernetes et d√©ployer Free5GC, plusieurs outils et composants doivent √™tre install√©s sur la machine virtuelle Ubuntu.

Les d√©pendances n√©cessaires dans le cadre de ce TP sont :

- **Docker** : moteur de conteneurs utilis√© par Kind pour cr√©er les n≈ìuds Kubernetes.
- **Kind (Kubernetes in Docker)** : permet de d√©ployer un cluster Kubernetes l√©ger bas√© sur des conteneurs.
- **Kubectl** : outil en ligne de commande permettant d‚Äôinteragir avec le cluster Kubernetes.
- **Helm** : gestionnaire de charts utilis√© pour d√©ployer Free5GC et UERANSIM.
- **GTP5G Kernel Module** : module noyau indispensable pour activer le tunneling GTP-U et permettre le fonctionnement de l‚ÄôUPF de Free5GC.
- **D√©p√¥t `towards5gs-helm`** : charts Helm fournis dans le cadre du TP pour d√©ployer automatiquement Free5GC et UERANSIM.

Les sous-sections suivantes d√©taillent la proc√©dure compl√®te d‚Äôinstallation de chacune de ces d√©pendances, avec les commandes ex√©cut√©es et les captures d‚Äô√©cran associ√©es.


---

## 2.2.1 Mise √† jour du syst√®me

La premi√®re √©tape consiste √† mettre √† jour Ubuntu afin de garantir la compatibilit√© des paquets :

``` bash
sudo apt udate
sudo apt upgrade -y 
```

![Mise √† jour du syst√®me](./docker/01_system_update.png)

---

## 2.2 Installation de Docker

Pour ce TP, j‚Äôai install√© Docker √† partir des d√©p√¥ts officiels Ubuntu, via le paquet `docker.io`.  
Cette m√©thode est simple, rapide et enti√®rement compatible avec l‚Äôutilisation de Kind.

Installation :



``` bash
 sudo apt install-y docker.io
```
![Installer docker](./docker/02_install_docker.png)

V√©rification de la version install√©e :

``` bash
docker --version
```
![Installer docker](./docker/02_02_installdocker.png)


Activation du Service Docker
``` bash
sudo systemctl enable docker
sudo systemctl start docker
sudo systemctl status docker
```

![Docker install√© et actif](./docker/03_docker_status.png)

## 2.3 Installation de Kind

Comme indiqu√© dans le TP, Kind doit √™tre install√© manuellement via un binaire plac√© dans le r√©pertoire `/usr/local/bin`.  
Kind (*Kubernetes in Docker*) permet de cr√©er un cluster Kubernetes directement √† l‚Äôint√©rieur de Docker.

### T√©l√©chargement de Kind

```bash
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.30.0/kind-linux-amd64
```
Rendre le binaire ex√©cutable

```bash
chmod +x ./kind
```
D√©placement dans le dossier /usr/local/bin
```bash
sudo mv ./kind /usr/local/bin/kind
```

V√©rification de l‚Äôinstallation

```bash
kind --version
```
![Installer kind](./dependances/01_installation_Kind.png)
## 2.4 Installation de Kubectl

T√©l√©charger Kubectl
```bash
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
```
Rendre ex√©cutable
```bash
chmod +x kubectl
```
D√©placer dans /usr/local/bin

```bash
sudo mv kubectl /usr/local/bin/
```
V√©rifier l'installation
```bash
kubectl version --client

```
![Installer kubectl](./dependances/02_installation_kubectl.png)



## 2.5 Instalaltion de Helm

Installation Helm via script officiel 
```bash
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
```
V√©rifier l'installation
```bash
helm version
```
![Installer helm](./dependances/03_installation_helm.png)
## 2.6 Installation du module noyau GTP5G
L‚Äôinstallation du module noyau **gtp5g** est indispensable pour permettre le routage GTP-U utilis√© par l‚ÄôUPF dans Free5GC.  
Ce module permet la gestion des tunnels et du forwarding des paquets sur les interfaces N3 et N6.

Installer les outils de compilations
```bash
sudo apt install -y git make gcc linux-headers-$(uname -r)
```
T√©l√©charger GTP5G
```bash
git clone https://github.com/free5gc/gtp5g.git
```
Compiler le module noyau
```bash
cd gtp5g
make clean
make
```
Installer le module 
```bash
sudo make install 
```
V√©rifier que le module est bien install√© 
```bash
lsmod | grep gtp5g
```
![Instllation du noyau GTP5](./dependances/04_installation_noyau5G.png)


## 2.7 Clonage du d√©p√¥t towards5gs-helm
Le TP utilise le d√©p√¥t GitHub *towards5gs-helm*, qui contient l‚Äôensemble des charts Helm n√©cessaires pour d√©ployer Free5GC et UERANSIM dans le cluster Kubernetes.

Parmis les √©tapes √† suivre :

Se mettre dans le r√©pertoir $HOME

```bash
cd ~
```
Cloner le d√©p√¥t depuis GitHub 
```bash
git clone https://github.com/cdestre/towards5gs-helm.git
# V√©rifier qu'il existe
ls
```
![clonage du depot](./dependances/05_git_clone_repo.png)

# 3. Cr√©ation du cluster KinD

Apr√®s l‚Äôinstallation des d√©pendances, l‚Äô√©tape suivante consiste √† cr√©er un cluster Kubernetes bas√© sur Kind.  
Le TP impose l‚Äôutilisation d‚Äôun fichier de configuration pour d√©finir la structure du cluster, compos√© de deux n≈ìuds :

- un n≈ìud **control-plane**
- un n≈ìud **worker**

---

## 3.1 Cr√©ation du fichier de configuration `mycluster.yaml`

```bash
nano mycluster.yaml
```
Le fichier de configuration suivant d√©crit la topologie du cluster :

```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
  - role: worker


```
![cr√©ation fichier yaml](./cluster/01_mycluster_yaml.png)

Cr√©ation du cluster kind

```bash
sudo kind create cluster --config mycluster.yaml
```
![cr√©ation cluster kind](./cluster/02_creation_cluster.png)

V√©rification des n≈ìuds Kubernetes:

```bash
# toujours mettre sudo
sudo kubectl get nodes 
```
![nodes](./cluster/03_nodes_kubernetes.png)
## 3.4 Installation manuelle des plugins CNI
Comme indiqu√© dans le TP, Kind ne fournit pas de plugins CNI par d√©faut.  
Il est donc n√©cessaire de t√©l√©charger et d‚Äôinstaller manuellement les plugins r√©seaux utilis√©s par Kubernetes.

### T√©l√©chargement et extraction des plugins CNI

```bash
wget https://github.com/containernetworking/plugins/releases/download/v1.6.0/cni-plugins-linux-amd64-v1.6.0.tgz

# Puis extraire 
tar -xvf cni-plugins-linux-amd64-v1.6.0.tgz

```
![telechargerment_cni](./cluster/04_cni_extract.png)

### Identification des conteneurs Kind


```bash
sudo docker ps
```
![les_ids](./cluster/05_docker_ps_nodes.png)
Une fois les IDs r√©cup√©r√©s, j‚Äôai copi√© les plugins CNI vers chacun des n≈ìuds :
```bash
sudo docker cp . 97199854493c:/opt/cni/bin/  #control
sudo docker cp . efced09c7e28:/opt/cni/bin/ #worker

```
![docker_cp_cni](./cluster/06_docker_cp_cni.png)

V√©rification des interfaces r√©seau du worker 

```bash
sudo docker exec -it efced09c7e28 /bin/bash


# √Ä l'int√©rieur du conteneur
ip a
ip r

exit

```
Cette √©tape est importante car les informations r√©cup√©r√©es seront utilis√©es plus tard lors de la configuration de Free5GC ‚Äî notamment pour l‚ÄôUPF, qui doit conna√Ætre :

- la gateway du worker : **172.18.0.2**
- l‚Äôinterface du worker pour le r√©seau N6 : **eth0**

Et l‚Äôinterface eth0 du worker pour la N6
![addr_ip_worker](./cluster/07_worker_ip.png)
---


## 4. Installation de Multus CNI

Free5GC n√©cessite plusieurs interfaces r√©seau pour pouvoir communiquer sur les diff√©rents plans (N2, N3, N4, N6).  
Pour cela, le TP impose l‚Äôinstallation du plugin **Multus CNI**, qui permet d‚Äôattacher plusieurs interfaces r√©seau √† un m√™me pod.

---

## 4.1 D√©ploiement de Multus

Comme demand√© dans le TP, j‚Äôai commenc√© par cloner le d√©p√¥t officiel de Multus :

```bash
git clone https://github.com/k8snetworkplumbingwg/multus-cni
cd multus-cni
cat ./deployments/multus-daemonset-thick.yml | sudo kubectl apply -f -
```
Cette commande d√©ploie :

 - le CRD network-attachment-definitions

 - les r√¥les RBAC n√©cessaires

 - le ConfigMap de Multus

 - le DaemonSet kube-multus-ds
![installation_multus](./cluster/08_multus_node_annotation.png)
## 4.2 V√©rification du DaemonSet Multus

Pour v√©rifier que Multus est bien install√© sur les n≈ìuds :

```bash
sudo kubectl describe node kind-worker | grep -i multus
```
- La pr√©sence du pod kube-multus-ds-xxxx confirme que Multus fonctionne.
![multus_ready](./cluster/multus_fonctionne.png)
## 4.3 V√©rification des fichiers CNI sur les n≈ìuds

Apr√®s le d√©ploiement de Multus, il est important de v√©rifier que les fichiers de configuration CNI sont bien pr√©sents sur chacun des n≈ìuds du cluster Kind.  
Ces fichiers confirment que :

- **Kindnet** est bien install√© comme CNI primaire.
- **Multus** est bien install√© comme m√©ta-CNI permettant les interfaces secondaires.

Les commandes suivantes permettent d‚Äôinspecter le contenu du r√©pertoire `/etc/cni/net.d/` de chaque n≈ìud :

```bash
# N≈ìud control-plane
sudo docker exec -it 97199854493c ls /etc/cni/net.d/

# N≈ìud worker
sudo docker exec -it efced09c7e28 ls /etc/cni/net.d/
```
![file_config](./cluster/09_deploy_multus.png)

# 5. Installation et configuration de Free5GC

Dans cette section, nous installons Free5GC sur un cluster Kubernetes KinD, apr√®s avoir pr√©par√© :

- le stockage MongoDB

- le r√©seau Multus N6

- les valeurs UPF sp√©cifiques √† KinD

- le namespace free5gc

* L'installation se fait enti√®rement via Helm.

## 5.1 Installation de Multus CNI
Multus permet l‚Äôattachement de plusieurs interfaces r√©seau √† un pod, ce qui est indispensable pour l‚ÄôUPF de Free5GC.
, c'est une partie d√©j√† fini sur la section de haut 

## 5.2 Pr√©paration du stockage MongoDB
Free5GC utilise MongoDB comme base de donn√©es.
Pour garantir un d√©ploiement stable et fonctionnel, il est n√©cessaire de pr√©parer correctement le chart MongoDB avant l‚Äôinstallation de Free5GC.

Cette section pr√©sente les bonnes pratiques, sous forme de sous-√©tapes claires :

- V√©rifier et extraire le sous-chart MongoDB

- Modifier les param√®tres de l‚Äôimage MongoDB

- Cr√©er le dossier de stockage local dans le worker

- Cr√©er et appliquer un PersistentVolume

- V√©rifier que le PV est bien pris en compte

### 5.2.1 V√©rification et extraction du sous-chart MongoDB

- Le chart Free5GC contient un sous-chart mongodb situ√© dans :
```bash
cd ~/towards5gs-helm/charts/free5gc/charts

# Dans certains cas, ce sous-chart est fourni sous forme d‚Äôarchive .tgz.
# Il faut alors le d√©compresser :

cd ~/towards5gs-helm/charts/free5gc/charts
tar -xvf mongodb-*.tgz

```
![deziper_mongo](./5Gfree/05_dezip_mongo.png)

Apr√®s extraction, on v√©rifie la pr√©sence du dossier mongodb/, contenant notamment :
- values.yaml (fichier de configuration principal)
- templates/ (d√©finition du StatefulSet MongoDB)

![info_mongodb](./5Gfree/05_.2.png)
#### 5.2.1.1 Modification du fichier values.yaml  
Ouvrir le fichier :
```bash
nano mongodb/values.yaml

```
Au d√©but du fichier, la configuration par d√©faut utilise :

```yaml
 ## Au d√©but 
image:
  registry: docker.io
  repository: bitnami/mongodb
  tag: 4.4.4-debian-10 # ici faut changer l'image 
```
 ![structure_mongo](./5Gfree/01_etat_ini_mongo.png)
- Par :
```yaml
repository: mongo
tag: 4.4
```
![solution_monfdb](./5Gfree/solution_mongo.png)

<!-- ###################################### -->
### 5.2.2 Cr√©ation du dossier de stockage dans le worker
MongoDB n√©cessite un volume persistant.
Dans un cluster KinD, ce stockage doit √™tre cr√©√© manuellement dans le conteneur du n≈ìud worker.
```bash
sudo docker exec -it kind-worker mkdir /home/kubedata

```
### 5.2.3 Cr√©ation et application du PersistentVolume (PV)
- Dans $HOME  cr√©er le fichier suivant : 
```bash
~> nano volume.yaml

```
- Avec le contenu suivant :
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: example-local-pv9
  labels:
    project: free5gc
spec:
  capacity:
    storage: 8Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  local:
    path: /home/kubedata
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - kind-control-plane

```
- Appliquer le volume 
```bash
sudo kubectl apply -f volume.yaml
sudo kubectl get pv
```
![pv_yes](./5Gfree/01_pv.png)

## 5.3 D√©finition du r√©seau N6 (Multus)
Le r√©seau N6 correspond √† l‚Äôinterface de sortie de l‚ÄôUPF vers le Data Network (Internet ou LAN).
Multus est utilis√© pour attacher une interface r√©seau suppl√©mentaire au pod UPF.
- Cr√©er le fichier :
```bash
# cr√©er le fichier n6network.yaml dans le home
nano n6network.yaml
```
- Avec le contenu :
```yaml
apiVersion: "k8s.cni.cncf.io/v1"
kind: NetworkAttachmentDefinition
metadata:
  name: n6network
  namespace: free5gc
spec:
  config: '{
    "cniVersion": "0.3.1",
    "type": "ipvlan",
    "mode": "l2",
    "master": "eth0",
    "ipam": {
      "type": "static",
      "addresses": [
        {
          "address": "172.18.0.22/16",
          "gateway": "172.18.0.1"
        }
      ]
    }
  }'

```
- Appliquer 
```bash
# cr√©ation du namespace free5gc
sudo kubectl create ns free5gc

# appliquer le r√©seau N6
sudo kubectl apply -f n6network.yaml --validate=false

# v√©rifier avec cette commande  seulement les NAD de ce namespace (free5gc)
sudo kubectl get network-attachment-definitions -n free5gc


```
![n6](./5Gfree/02_N6.png)






## 5.4 Configuration sp√©cifique Free5GC (UPF + r√©seaux)
### 5.4.1 Identification du r√©seau KinD
Pour configurer correctement l‚ÄôUPF, nous devons conna√Ætre :

- l‚Äôinterface r√©seau du worker

- l‚Äôadresse IP du worker

- la gateway Docker/Kind

Commande :
```bash
sudo docker exec -it kind-worker bash
ip a
ip r
exit
```
R√©sultat observ√© comme vu prec√©dement :

- interface principale : eth0

- r√©seau Kind : 172.18.0.0/16

- gateway : 172.18.0.1
### 5.4.2 Configuration de l‚ÄôUPF (free5gc-upf/values.yaml)
Dans le chart Free5GC, chaque fonction r√©seau poss√®de son propre sous-chart.
L‚ÄôUPF doit obligatoirement conna√Ætre l‚ÄôIP de son interface N6 :
```bash
cd ~/towards5gs-helm/charts/free5gc/charts/free5gc-upf/
nano values.yaml
```
- Modifier :
```yaml
n6if:
  ipAddress: 172.18.0.22
```
![n6if](./5Gfree/n6if.png)
### 5.4.3 Configuration du N6 dans le chart Free5GC
En plus de la cr√©ation du fichier n6network.yaml, il est n√©cessaire d‚Äôinformer Free5GC qu‚Äôil doit utiliser ce r√©seau Multus pour l‚Äôinterface N6 de l‚ÄôUPF.

Pour cela, il faut modifier le fichier values.yaml du chart principal Free5GC.
- √âtape 1 : ouvrir le fichier
```bash
cd ~/towards5gs-helm/charts/free5gc
nano values.yaml

```
- √âtape 2 : localiser la section n6network:
```yaml
n6network:
  enabled: true
  name: n6network

```
- √âtape 3 : Les champs suivants doivent √™tre modifi√©s en fonction du r√©seau observ√© sur le worker :
```yaml
n6network:
  enabled: true
  name: n6network               # doit √™tre identique au NAD cr√©√© ("n6network")
  type: ipvlan
  masterIf: eth0                # interface observ√©e dans le worker
  subnetIP: 172.18.0.0          # sous-r√©seau d√©duit du worker
  cidr: 16                      # masque (/16 ‚Üí 255.255.0.0)
  gatewayIP: 172.18.0.1         # gateway observ√©e dans 'ip r'
  exludeIP: 172.18.0.0
```
![n6netwpojr](./5Gfree/n6network.png)

## 5.5 Installation de Free5GC via Helm
Une fois le stockage MongoDB et le r√©seau Multus configur√©s, nous pouvons installer Free5GC gr√¢ce au chart Helm fourni dans le d√©p√¥t towards5gs-helm.

- Le chart Free5GC installe automatiquement les fonctions suivantes :
  - AMF -> Network 2
  - SMF -> Network 4 
  - UPF (avec l‚Äôinterface N6) -> Network 6
  - AUSF
  - UDM
  - UDR
  - PCF
  - NRF
  - WebUI

- Commande d‚Äôinstallation :
```bash
# Il  faut obligatoirement se situer sur ce repertoir 
cd ~/towards5gs-helm/charts

# Installation dans le namespace free5gc
sudo helm -n free5gc install free5gc-premier ./free5gc/


# Ensuite, v√©rifier l‚Äô√©tat des pods :
sudo kubectl get pods -n free5gc

```
![deziper](./5Gfree/05_dezip_mongo.png)
ensuite chercher le dossier mongodb afin de modifier le fichier value 
![mongo](./5Gfree/05_.2.png)
 modifier le fichier volume.yaml
Avant : 
![volume](./5Gfree/06_mongo_2.png)
Apr√©s modification 
![volume2](./5Gfree/06_value_mongo.png)
ensuite on recpee l'image r√©cente mongo:4.4
```bash
# T√©l√©charger l'image dans la vm 
sudo docker pull mongo:4.4
# Charger l'image dans le cluster kind
sudo kind load docker-image mongo:4.4 --name kind

# Supprimer l‚Äôancien StatefulSet MongoDB
sudo kubectl delete pvc -n free5gc --all
sudo kubectl delete pv example-local-pv9

# Partie sur $HOME
cd 

sudo kubectl apply -f volume.yaml

# ensuite reinstaller free5GC
cd ~/towards5gs-helm/charts
sudo helm -n free5gc install free5gc-premier ./free5gc/

```
## 5.5 Installation de Free5GC via Helm
- Une fois MongoDB pr√™t, Multus configur√© et l‚ÄôUPF ajust√©, on peut lancer l‚Äôinstallation :
```bash
# Toujours se mettre sur ce repertoir

cd ~/towards5gs-helm/charts

sudo helm -n free5gc install free5gc-premier ./free5gc/

# V√©rification :
sudo kubectl get pods -n free5gc
```
![mongo_run](./5Gfree/07_mongo_run.png)


## 5.7 ‚Äì Acc√®s √† l‚Äôinterface WebUI de Free5GC
Lorsque les pods Free5GC sont en √©tat Running , nous pouvons acc√©der √† l‚Äôinterface WebUI afin de visualiser les UEs, les sessions PDU et la configuration du Core.

### 5.7.1 Pr√©paration : cr√©er un tunnel SSH SOCKS5
Pour acc√©der au WebUI depuis notre machine Windows, nous utilisons un tunnel SSH via l‚Äôoption -D (SOCKS proxy).

- Dans git bash 
```bash
ssh -D 8080 -N tyna@127.0.0.1 -p 2222
```
![tunnel_ssh](./5Gfree/vm_pour%20lancer%20navigateur.png)
Cette commande :

- cr√©e un proxy SOCKS5 local sur 127.0.0.1:8080

- sans ouvrir de session (-N)

- en utilisant le port SSH redirig√© via VMware (-p 2222)
### 5.7.2 Configuration du navigateur
Nous devons indiquer √† Firefox/Chrome dans pram√®tre r√©seau  d‚Äôutiliser le proxy SOCKS5 :

- Adresse : 127.0.0.1

- Port : 8080

- Type : SOCKS5

- Activer Proxy DNS
![proxy](./5Gfree/proxy.png)
### 5.7.3 Acc√®s au WebUI
- Une fois le proxy configur√©, nous pouvons acc√©der √† l‚Äôinterface :
```cpp
http://172.18.0.2:5000

```
- Cette adresse correspond √† l‚ÄôIP du n≈ìud worker du cluster KinD obtenue avec :
```bash
sudo docker exec -it kind-worker ip a
```
### 5.7.4 Connexion au WebUI
Identifiants par d√©faut du chart :

- username : admin

- password : free5gc
![web_ui](./5Gfree/ue_final.png)
### 5.7.5 Ajout d‚Äôun utilisateur UE (WebUI)
L'√©tape suivante consiste √† cr√©er un utilisateur (IMSI, cl√©, OPc, etc.).
Dans WebUI ‚Üí Subscriber Management, j‚Äôai ajout√© le profil d‚ÄôUE fourni dans l‚Äô√©nonc√©.
![subscribe](./5Gfree/final_subscribe_1ure%20d'√©c.png)
![subscribe](./5Gfree/final_subscribe_2.png)


Dans l‚Äôinterface Subscriber Management, on voit que l‚Äôutilisateur a bien √©t√© ajout√© dans Free5GC (profil IMSI, cl√©s, OPc, etc.).
Cependant, l‚ÄôUE n‚Äôest pas encore enregistr√© dans le r√©seau 5G :
l‚Äôinscription (registration) ne sera effectu√©e que lorsque UERANSIM simulera effectivement l‚ÄôUE.
√Ä ce stade, l‚Äôutilisateur est pr√©sent dans la base de donn√©es, mais pas encore attach√© au c≈ìur 5G.
## 5.8 ‚Äì D√©ploiement d‚ÄôUERANSIM (gNB + UE simul√©s)
Pour permettre l‚Äôenregistrement de l‚ÄôUE dans Free5GC, nous devons d√©ployer le simulateur RAN UERANSIM (gNB + UE).

Il est important d‚Äôinstaller UERANSIM dans le m√™me namespace que Free5GC, c‚Äôest-√†-dire free5gc, afin que les composants puissent communiquer correctement.

### 5.8.1 Installation du chart UERANSIM

- Comme pour Free5GC, l‚Äôinstallation se fait depuis le r√©pertoire charts :
```bash
cd ~/towards5gs-helm/charts
sudo helm -n free5gc install ueransim-premier ./ueransim/
```
Cette commande installe automatiquement :

- un gNB simul√©,

- un UE simul√©,

- configure les communications NGAP/NRR entre gNB ‚Üî AMF.
![create_ue](./5Gfree/ueransim_ccreate.png)

### 5.8.2 V√©rification des pods UERANSIM
- Une fois l‚Äôinstallation termin√©e :
```bash
sudo kubectl get pods -n free5gc

```
![ue_run](./5Gfree/5_7resultat_ue.png)

![registrer$d](./5Gfree/registred_final.png)

![registrer$d](./5Gfree/registred_part1.png)

![registrer$d](./5Gfree/registred_part2.png)

### 5.8.3 Lien avec Free5GC
Une fois UERANSIM lanc√©, plusieurs √©changes automatiques s‚Äôeffectuent entre le gNB, l‚ÄôUE et le c≈ìur Free5GC :

- le gNB envoie un NG Setup Request √† l‚ÄôAMF pour √©tablir le lien RAN ‚Üî Core ;

- l‚ÄôUE d√©marre une proc√©dure 5G Registration aupr√®s de l‚ÄôAMF ;

- Free5GC effectue l‚ÄôAuthentication et le Security Mode Control ;

- l‚ÄôUE re√ßoit un Registration Accept et devient enregistr√© ;

- lorsqu‚Äôune PDU Session est cr√©√©e, une interface virtuelle uesimtun0 appara√Æt dans le pod UE, repr√©sentant le tunnel GTP-U vers l‚ÄôUPF.

Ces √©changes seront v√©rifi√©s dans la section suivante √† l‚Äôaide des tests fonctionnels.
# 6 Tests de validation du r√©seau 5G Free5GC
 Apr√®s le d√©ploiement complet du c≈ìur 5G (AMF, SMF, UPF, NRF, UDM, UDR, PCF) et du RAN simul√© UERANSIM (gNB + UE), nous validons maintenant le fonctionnement du r√©seau :

Plan de contr√¥le : Registration 5G, Authentication, Security Mode Control

Plan utilisateur : √©tablissement d‚Äôune PDU session, cr√©ation de uesimtun0, trafic vers l‚ÄôUPF

Les tests suivants prouvent que l‚ÄôUE est correctement enregistr√© et que le tunnel GTP-U fonctionne.


## 6.1  R√©cup√©ration du nom du pod UE
 ```bash
 export POD_NAME=$(sudo kubectl get pods --namespace free5gc -l "component=ue" -o jsonpath="{.items[0].metadata.name}")
 ```
- Explication :
  - Cette commande r√©cup√®re automatiquement le nom du pod UERANSIM-UE gr√¢ce au label component=ue et le stocke dans la variable $POD_NAME.

R√©sultat obtenu dans notre environnement :
 ![var_pod](./5Gfree/var_pod_name.png)

## 6.2 V√©rification de la cr√©ation de l‚Äôinterface TUN c√¥t√© UE
### 6.2.1 Lecture des logs UE

```bash
sudo kubectl --namespace free5gc logs $POD_NAME

```
- Explication :
  - Ce que l‚Äôon v√©rifie dans les logs :

  - NG Setup entre gNB ‚Üî AMF

  - Registration Request ‚Üí Accept

  - Authentication OK

  - Security Mode OK

  - Cr√©ation d‚Äôune session PDU

 ![var_pod_in](./5Gfree/6.2.1_init.png)

### 6.2.2 V√©rification de l‚Äôinterface uesimtun0

```bash
sudoo kubectl --namespace free5gc exec -it $POD_NAME -- ip address
```

- Explication :
  - Cette commande permet de v√©rifier la pr√©sence et l‚Äô√©tat de l‚Äôinterface uesimtun0, qui symbolise le tunnel GTP/UPF ‚Üí UE.

- R√©sultat obtenu :

 ![var_pod_in](./5Gfree/ue_ths.png)
 Conclusion : l‚ÄôUE est attach√© et dispose d‚Äôune IP 5G.

## 6.3 Test du trafic utilisateur (plan utilisateur - UP)

### 6.3.1 Ping vers l‚Äôinterface N6 de l‚ÄôUPF
```bash
sudo kubectl --namespace free5gc exec -it $POD_NAME -- ping -I uesimtun0 172.18.0.22
```
- Objectif : v√©rifier que les paquets sortent bien via le tunnel 5G et atteignent l‚ÄôUPF sur son interface N6.

![test_cnx](./5Gfree/test-6.3.png)
Conclusion : la session PDU est active et fonctionnelle.

# 6.4 Test de sortie Internet
```bash
sudo kubectl --namespace free5gc exec -it $POD_NAME -- ping -I uesimtun0 www.google.com
```

![google](./5Gfree/test_google.png)
Oui, ton rapport est **logique**, **coh√©rent**, et ce que tu veux ajouter dans la partie ‚ÄúErreurs rencontr√©es‚Äù est **parfaitement pertinent**.

Voici comment organiser proprement cette section *exactement comme dans un vrai rapport de TP Free5GC*, en int√©grant :

* l‚Äôerreur sur MongoDB
* l‚Äôerreur sur le cluster KinD
* l‚Äôerreur sur `$POD_NAME`
* l‚Äôerreur `ImagePullBackOff`
* l‚Äôerreur UPF (normal avant configuration N6)
* l‚Äôerreur NAT/Google (optionnelle)

Je te donne une version **propre, structur√©e, pr√™te √† coller dans ton rapport**, en reprenant **tes captures**, **tes textes**, mais corrig√©, organis√© et coh√©rent.

---

# 7 Probl√®mes rencontr√©s et solutions apport√©es

Cette section pr√©sente les principales erreurs rencontr√©es lors du d√©ploiement de Free5GC et d‚ÄôUERANSIM, ainsi que les solutions mises en place pour aboutir √† un fonctionnement complet du r√©seau 5G.

---

## 7.1 Probl√®me : MongoDB en `ImagePullBackOff`
![err](./5Gfree/01_mongodb.png)

### **Sympt√¥me**

Lors de l‚Äôinstallation initiale du chart Free5GC, MongoDB reste en :

```
ImagePullBackOff
```

### **Cause**

Le sous-chart MongoDB utilise par d√©faut l‚Äôimage **bitnami/mongodb**, qui n‚Äôest plus compatible avec l‚Äôenvironnement KinD (permissions, user non-root, probes trop strictes).

### **Analyse du fichier `values.yaml`**

Configuration initiale :

```yaml
image:
  registry: docker.io
  repository: bitnami/mongodb
  tag: 4.4.4-debian-10
```

Et des probes trop strictes :

```yaml
livenessProbe:
  enabled: true
readinessProbe:
  enabled: true
```

### **Solution**

1. D√©zipper le sous-chart MongoDB
2. Modifier `mongodb/values.yaml` :

```yaml
repository: mongo
tag: 4.4
livenessProbe:
  enabled: false
readinessProbe:
  enabled: false
```

3. Charger manuellement l‚Äôimage dans KinD :

```bash
sudo docker pull mongo:4.4
sudo kind load docker-image mongo:4.4 --name kind
```

4. Recr√©er le PV + r√©installer Free5GC.

### **R√©sultat**

MongoDB passe en √©tat :

```
Running
```

- Free5GC peut d√©marrer correctement.

---

## 7.2 Explication du test de connectivit√© UE ‚Üí UPF
Voici **exactement ce que tu m‚Äôas demand√©** :
‚û°Ô∏è **le texte en Markdown**, propre, clair, pr√™t √† coller dans ton rapport
‚û°Ô∏è **bas√© uniquement sur TA capture**, avec une explication simple pour un d√©butant.

Tu n‚Äôas qu‚Äô√† copier-coller :

---

# üìå **Explication du test de connectivit√© UE ‚Üí UPF**

### **Capture :**

![test\_ue](./5Gfree/7.ping.jpg)

---

 **Analyse et explication**

Cette capture montre les trois √©tapes essentielles du fonctionnement du tunnel 5G entre l‚ÄôUE (UERANSIM) et le UPF de Free5GC.

---

 **1Ô∏è Premier test : Ping trop t√¥t ‚Üí erreur normale**

Commande ex√©cut√©e :

```bash
sudo kubectl --namespace free5gc exec -it $POD_NAME -- ping -I uesimtun0 www.google.com
```

- R√©sultat :

```
ping: usage error: Destination address required
command terminated with exit code 1
```

###  Pourquoi cette erreur appara√Æt ?

√Ä ce moment :

* l‚ÄôUE **n‚Äô√©tait pas encore enregistr√©** dans Free5GC (Registration incomplet),
* **aucune Session PDU** n‚Äô√©tait encore √©tablie,
* l‚Äôinterface virtuelle **uesimtun0 n‚Äôexistait pas encore**.

**C‚Äôest normal : aucun ping n‚Äôest possible tant que l‚ÄôUE n‚Äôa pas obtenu son IP 5G.**

---

 **2Ô∏è Deuxi√®me test : V√©rification des interfaces r√©seau**

Commande :

```bash
kubectl exec -it -n free5gc $POD_NAME -- ip addr
```

- R√©sultat :
On voit appara√Ætre l‚Äôinterface :

```
3: uesimtun0: ...
    inet 10.1.0.1/32 scope global uesimtun0
```

###  Ce que cela signifie

* L‚ÄôUE a maintenant **re√ßu une adresse IP 5G** (`10.1.0.1`),
* Le tunnel GTP-U entre le gNB ‚Üí UPF ‚Üí UE est **cr√©√©**,
* La session PDU est **active**, donc le plan utilisateur fonctionne.

- **L‚ÄôUE est correctement attach√© au r√©seau 5G.**

---

 **3Ô∏è Troisi√®me test : Ping du UPF (interface N6) ‚Üí Succ√®s**

Commande :

```bash
sudo kubectl exec -it -n free5gc $POD_NAME -- ping -I uesimtun0 172.18.0.22
```

- R√©sultat :

```
64 bytes from 172.18.0.22: time=1.32 ms
64 bytes from 172.18.0.22: time=1.94 ms
64 bytes from 172.18.0.22: time=5.27 ms
```

###  Interpr√©tation

* `172.18.0.22` = adresse N6 du UPF
* Le ping passe **via uesimtun0**
* Les temps de r√©ponse sont faibles et stables

 **Preuve que le trafic passe correctement par le UPF.**


![err_net](./5Gfree/7.ping.jpg)

### **Sympt√¥me**

La variable montre un nom incorrect :

```
ueransim-premier-ue-6fdbccb8cf-pjtqr
```

Au lieu de celui visible avec :

```bash
kubectl get pods -n free5gc
```

### **Cause**

Le label utilis√© dans la commande √©tait erron√©.

### **Solution**

Utiliser le bon label du chart UERANSIM :

```bash
export POD_NAME=$(kubectl get pods -n free5gc -l "component=ue" -o jsonpath="{.items[0].metadata.name}")
```

### **R√©sultat**

La variable correspond bien au pod UE actif.

---

## 7.3 Probl√®me : Erreur √† la cr√©ation du cluster KinD

### **Sympt√¥me**

Apr√®s cr√©ation :

```
kubectl get nodes
‚Üí connection refused 127.0.0.1:XXXXX
```

### **Cause**

Le fichier kubeconfig n‚Äô√©tait pas appliqu√© (bug fr√©quent de KinD).

### **Solution**

Red√©marrer l‚ÄôAPI ou recr√©er le cluster :

```bash
kind delete cluster
kind create cluster --config mycluster.yaml
```

---

## 7.4 Probl√®me : UPF en `CrashLoopBackOff`

![loop-upf)](./5Gfree/Final_mongo_db_run.png)

### **Sympt√¥me**

```
free5gc-upf ‚Üí CrashLoopBackOff
```

### **Cause**

Normal :
 l‚ÄôUPF ne peut pas se lancer tant que **N6 n‚Äôest pas configur√©** :

* `NetworkAttachmentDefinition` manquante
* `n6if.ipAddress` non renseign√©

### **Solution**

1. Cr√©er le fichier **n6network.yaml**
2. Modifier dans `free5gc-upf/values.yaml` :

```yaml
n6if:
  ipAddress: 172.18.0.22
```

3. Activer N6 dans `free5gc/values.yaml`

```yaml
n6network:
  enabled: true
  name: n6network
  subnetIP: 172.18.0.0
  cidr: 16
  gatewayIP: 172.18.0.1
```

### **R√©sultat**

L‚ÄôUPF passe en **Running**, et UERANSIM peut s‚Äôenregistrer.

---
